use pyo3::prelude::*;
use pyo3::types::PyModule;
use pyo3::Bound;
use fnv::FnvHashSet;
use std::fs::File; // Rust íŒŒì¼ ì‹œìŠ¤í…œ ëª¨ë“ˆ
use std::io::{BufRead, BufReader}; // ë²„í¼ë§ëœ ì½ê¸° ë„êµ¬

// 1. DataCleanser êµ¬ì¡°ì²´
#[pyclass]
pub struct DataCleanser {
    pub seen_texts: FnvHashSet<String>,
    pub toxic_keywords: FnvHashSet<String>, // í˜•ë‹˜ì´ ì¶”ê°€í•˜ì‹  ê¸°ëŠ¥ ìœ ì§€!
}

// 2. DataCleanser ë©”ì†Œë“œ êµ¬í˜„
#[pymethods]
impl DataCleanser {
    #[new]
    fn new() -> Self {
        let mut toxic_keywords = FnvHashSet::default();
        toxic_keywords.insert("badword1".to_string());
        toxic_keywords.insert("badword2".to_string());
        toxic_keywords.insert("offensive_term".to_string());

        DataCleanser {
            seen_texts: FnvHashSet::default(),
            toxic_keywords,
        }
    }

    /// í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ê³  ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
    pub fn clean_text(&mut self, text: String) -> PyResult<Option<String>> {
        // 1. ì •ê·œí™” (Normalization)
        let normalized_key = text
            .replace('Â ', " ")
            .trim()
            .to_lowercase();

        // 2. í•„í„°ë§ (Filtering) - ë¬¸ì ìˆ˜ ê¸°ì¤€ (20ì ë¯¸ë§Œ)
        const MIN_LENGTH: usize = 20;
        if normalized_key.chars().count() < MIN_LENGTH {
            // eprintln!("Filtered length: {}", normalized_key); // ë””ë²„ê¹… í•„ìš”ì‹œ ì£¼ì„ í•´ì œ
            return Ok(None);
        }

        // ìœ í•´ ì½˜í…ì¸  í•„í„°ë§ (í˜•ë‹˜ì´ ë§Œë“œì‹  ë¡œì§!)
        for keyword in &self.toxic_keywords {
            if normalized_key.contains(keyword) {
                // eprintln!("Filtered toxic: {}", normalized_key);
                return Ok(None);
            }
        }

        // 3. ì¤‘ë³µ ì²´í¬ (Deduplication)
        if self.seen_texts.contains(&normalized_key) {
            Ok(None)
        } else {
            self.seen_texts.insert(normalized_key);
            Ok(Some(text)) // ì›ë³¸ ë°˜í™˜
        }
    }

    // ğŸ”¥ [í•µì‹¬] ê³ ì„±ëŠ¥ íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    // Python íŒŒì¼ ê°ì²´ ëŒ€ì‹ , íŒŒì¼ ê²½ë¡œ(path)ë¥¼ ë°›ì•„ì„œ Rustê°€ ì§ì ‘ ì—½ë‹ˆë‹¤.
    pub fn process_file(&mut self, path: String) -> PyResult<usize> {
        // Rustì˜ File I/Oë¥¼ ì‚¬ìš©í•˜ë©´ Python GILê³¼ ìƒê´€ì—†ì´ ì—„ì²­ë‚˜ê²Œ ë¹ ë¦…ë‹ˆë‹¤.
        // ë˜í•œ BufReaderë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì¡°ê¸ˆì”©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤ (Streaming).

        let file = File::open(path)?; // íŒŒì¼ ì—´ê¸° (ì‹¤íŒ¨ì‹œ ì—ëŸ¬ ë°˜í™˜)
        let reader = BufReader::new(file);
        let mut processed_lines = 0;

        for line in reader.lines() {
            // Rust Result ì²˜ë¦¬
            let text = match line {
                Ok(t) => t,
                Err(e) => return Err(pyo3::exceptions::PyIOError::new_err(e.to_string())),
            };

            // clean_text í˜¸ì¶œ
            // unwrap_or(None).is_some() íŒ¨í„´ìœ¼ë¡œ ìœ íš¨í•œ ë¬¸ì¥ë§Œ ì¹´ìš´íŠ¸
            if self.clean_text(text).unwrap_or(None).is_some() {
                processed_lines += 1;
            }
        }

        Ok(processed_lines)
    }

    // ì¶”ì  ê°œìˆ˜
    #[getter]
    pub fn count(&self) -> PyResult<usize> {
        Ok(self.seen_texts.len())
    }
}

// 3. ëª¨ë“ˆ ì§„ì…ì 
#[pymodule]
fn rust_core(m: &Bound<'_, PyModule>) -> PyResult<()> {
    m.add_class::<DataCleanser>()?;
    Ok(())
}
